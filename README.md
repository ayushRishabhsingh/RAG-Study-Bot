# ğŸ“š RAG Study Bot

A Retrieval-Augmented Generation (RAG) chatbot that answers questions based on your study materials and past papers using AI.

## ğŸŒŸ Features

- ğŸ“„ **PDF Processing**: Upload and process multiple PDF documents
- ğŸ” **Smart Search**: Uses vector similarity search to find relevant content
- ğŸ¤– **AI-Powered Answers**: Generates accurate answers using LLMs
- ğŸ’¾ **Cloud Storage**: Stores embeddings in Pinecone vector database
- ğŸ¨ **Beautiful UI**: Clean Streamlit interface

## ğŸ› ï¸ Tech Stack

- **Frontend**: Streamlit
- **Vector DB**: Pinecone
- **Embeddings**: Sentence Transformers (all-mpnet-base-v2)
- **LLM**: Groq (Llama 3.1) / Ollama (local)
- **Framework**: LangChain

## ğŸš€ Quick Start

### Local Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/YOUR_USERNAME/rag-study-bot.git
   cd rag-study-bot
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**:
   Create `.env` file:
   ```
   PINECONE_API_KEY=your_pinecone_key
   PINECONE_ENV=us-east-1-aws
   GROQ_API_KEY=your_groq_key
   ```

4. **Add your PDFs**:
   Place your study materials in the `papers/` folder

5. **Ingest documents**:
   ```bash
   python ingest.py
   ```

6. **Run the app**:
   ```bash
   streamlit run app.py
   ```

## ğŸ“¦ Project Structure

```
rag-xchatbpt/
â”œâ”€â”€ app.py                 # Main Streamlit app (local with Ollama)
â”œâ”€â”€ app_cloud.py          # Cloud-ready version (with Groq)
â”œâ”€â”€ ingest.py             # PDF ingestion script
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env                  # Environment variables (not in git)
â”œâ”€â”€ papers/               # Your PDF documents
â””â”€â”€ DEPLOYMENT_GUIDE.md   # Deployment instructions
```

## ğŸŒ Deployment

See [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for detailed deployment instructions.

**Quick Deploy to Streamlit Cloud:**
1. Push to GitHub
2. Connect to Streamlit Cloud
3. Add secrets (API keys)
4. Deploy!

## ğŸ”‘ API Keys Required

1. **Pinecone**: https://www.pinecone.io (Free tier available)
2. **Groq**: https://console.groq.com (Free API)

## ğŸ“– Usage

1. Upload your study materials (PDFs) to the `papers/` folder
2. Run `python ingest.py` to process and upload to Pinecone
3. Start the app with `streamlit run app.py`
4. Ask questions about your study materials!

## ğŸ¯ Example Questions

- "What are the key concepts in [topic]?"
- "Explain [specific concept] from the notes"
- "What are the important formulas for [subject]?"
- "Summarize the chapter on [topic]"

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

MIT License - feel free to use this project for your studies!

## ğŸ™ Acknowledgments

- LangChain for the RAG framework
- Pinecone for vector storage
- Groq for fast LLM inference
- Streamlit for the amazing UI framework

---

Made by Ayush Singh for students
